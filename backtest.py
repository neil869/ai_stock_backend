# backtest.py
import pandas as pd
import numpy as np
import time
import logging
from datetime import datetime, timedelta
import warnings
import os
import pickle

# é…ç½®logging
logger = logging.getLogger(__name__)

# è®¾ç½®akshareè¯·æ±‚å¤´
os.environ['AKSHARE_HEADERS'] = '{"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}'
warnings.filterwarnings('ignore')

try:
    import akshare as ak
    from lightgbm import LGBMClassifier
    from sklearn.utils.class_weight import compute_class_weight
    from data_fetch import get_stock_daily
    from predict import calc_features_safe
    from db import save_backtest_result, query_backtest_results
    from stock_utils import get_market_board
    # å¯¼å…¥äº¤æ˜“æ—¥å†ç›¸å…³åŠŸèƒ½ï¼ˆè¿™é‡Œæš‚æ—¶ä½¿ç”¨ç®€å•çš„åˆ¤æ–­ï¼Œåé¢ä¼šå¼•å…¥calendaræ¨¡å—ï¼‰
except ImportError as e:
    raise RuntimeError(f"Missing dependency: {e}")

# å›æµ‹ç¼“å­˜
_backtest_cache = {}
_last_backtest_update = {}

# ç¼“å­˜æ–‡ä»¶è·¯å¾„å®šä¹‰
BACKTEST_CACHE_FILE = 'backtest_cache.pkl'


# ==============================
# ğŸ“ ç¼“å­˜æœ¬åœ°æŒä¹…åŒ–åŠŸèƒ½
# ==============================
def load_backtest_cache():
    """
    ä»æ–‡ä»¶åŠ è½½å›æµ‹ç»“æœç¼“å­˜
    """
    global _backtest_cache, _last_backtest_update
    try:
        if os.path.exists(BACKTEST_CACHE_FILE):
            with open(BACKTEST_CACHE_FILE, 'rb') as f:
                data = pickle.load(f)
                if isinstance(data, dict) and 'cache' in data and 'last_update' in data:
                    _backtest_cache = data['cache']
                    _last_backtest_update = data['last_update']
                    logger.info(f"ä»æœ¬åœ°æ–‡ä»¶åŠ è½½å›æµ‹ç¼“å­˜æˆåŠŸï¼Œå…± {len(_backtest_cache)} æ¡æ•°æ®")
                    return True
    except Exception as e:
        logger.error(f"åŠ è½½å›æµ‹ç¼“å­˜å¤±è´¥ï¼š{e}")
    return False


def save_backtest_cache():
    """
    å°†å›æµ‹ç»“æœç¼“å­˜ä¿å­˜åˆ°æ–‡ä»¶
    """
    try:
        with open(BACKTEST_CACHE_FILE, 'wb') as f:
            pickle.dump({
                'cache': _backtest_cache,
                'last_update': _last_backtest_update
            }, f)
        logger.info(f"å›æµ‹ç¼“å­˜å·²ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œå…± {len(_backtest_cache)} æ¡æ•°æ®")
        return True
    except Exception as e:
        logger.error(f"ä¿å­˜å›æµ‹ç¼“å­˜å¤±è´¥ï¼š{e}")
    return False


# ==============================
# ğŸ“Š å›æµ‹åŠŸèƒ½
# ==============================
def backtest_ai_strategy(symbol, name, start_date='2023-01-01', end_date='2024-12-31', initial_capital=100000, transaction_cost=0.001):
    """
    å›æµ‹AIç­–ç•¥çš„æ€§èƒ½
    - symbol: è‚¡ç¥¨ä»£ç 
    - name: è‚¡ç¥¨åç§°
    - start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
    - end_date: å›æµ‹ç»“æŸæ—¥æœŸ
    - initial_capital: åˆå§‹èµ„é‡‘
    - transaction_cost: äº¤æ˜“æˆæœ¬
    """
    logger.info(f"å¼€å§‹å›æµ‹è‚¡ç¥¨ {symbol} ({name}) çš„AIç­–ç•¥")
    try:
        # è·å–è‚¡ç¥¨æ•°æ®
        df = get_stock_daily(symbol)
        if df is None or df.empty:
            logger.warning(f"[{symbol}] æ•°æ®ä¸è¶³æˆ–è·å–å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œå›æµ‹")
            return None

        # ç­›é€‰å›æµ‹æœŸé—´çš„æ•°æ®
        df = df[(df.index >= start_date) & (df.index <= end_date)]
        if len(df) < 200:
            logger.warning(f"[{symbol}] å›æµ‹æœŸé—´æ•°æ®ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œå›æµ‹")
            return None

        # åˆå§‹åŒ–å›æµ‹å‚æ•°
        capital = initial_capital
        shares = 0
        trades = []
        positions = []
        daily_values = []

        train_window = 100  # è®­ç»ƒçª—å£å¤§å°
        test_window = 10    # æµ‹è¯•çª—å£å¤§å°

        # åˆ†æ‰¹æ¬¡å›æµ‹
        for i in range(train_window, len(df), test_window):
            # è®­ç»ƒæ•°æ®
            train_end = i - 1
            train_data = df.iloc[:train_end+1]
            
            # æµ‹è¯•æ•°æ®
            test_start = i
            test_end = min(i + test_window - 1, len(df) - 1)
            test_data = df.iloc[test_start:test_end+1]

            if len(train_data) < 100 or len(test_data) < 1:
                continue

            # è®­ç»ƒæ¨¡å‹
            X_train = []
            y_train = []

            for j in range(60, len(train_data)):
                window_data = train_data.iloc[:j]
                feat = calc_features_safe(window_data)
                if feat is None:
                    continue
                X_train.append(feat)
                ret = (train_data.iloc[j]['close'] - train_data.iloc[j-1]['close']) / train_data.iloc[j-1]['close']
                y_train.append(int(ret > 0))

            if len(X_train) < 50:
                continue

            X_train = pd.DataFrame(X_train)
            y_train = np.array(y_train)

            # å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
            classes = np.unique(y_train)
            class_weight = dict(zip(classes, compute_class_weight('balanced', classes=classes, y=y_train))) if len(classes) == 2 else None

            # è®­ç»ƒæ¨¡å‹
            model = LGBMClassifier(
                n_estimators=80,
                max_depth=4,
                random_state=42,
                verbose=-1,
                class_weight=class_weight
            )
            model.fit(X_train, y_train)

            # å›æµ‹æµ‹è¯•é›†
            for idx, (date, row) in enumerate(test_data.iterrows()):
                # è®¡ç®—ç‰¹å¾
                window_data = df.iloc[:test_start+idx]
                feat = calc_features_safe(window_data)
                if feat is None:
                    continue

                # é¢„æµ‹ä¿¡å·
                prob = model.predict_proba([feat.reindex(X_train.columns, fill_value=0)])[0][1]
                
                # ç”Ÿæˆäº¤æ˜“ä¿¡å·
                signal = 0  # 0: æŒæœ‰, 1: ä¹°å…¥, -1: å–å‡º
                if prob > 0.6:
                    signal = 1
                elif prob < 0.4:
                    signal = -1

                # æ‰§è¡Œäº¤æ˜“
                if signal == 1 and shares == 0:
                    # ä¹°å…¥
                    shares_to_buy = capital // (row['close'] * 100) * 100
                    cost = shares_to_buy * row['close'] * (1 + transaction_cost)
                    if cost <= capital:
                        shares = shares_to_buy
                        capital -= cost
                        trades.append({
                            'date': date,
                            'action': 'buy',
                            'price': row['close'],
                            'shares': shares_to_buy,
                            'capital': capital,
                            'total_value': capital + shares * row['close']
                        })
                elif signal == -1 and shares > 0:
                    # å–å‡º
                    proceeds = shares * row['close'] * (1 - transaction_cost)
                    capital += proceeds
                    trades.append({
                        'date': date,
                        'action': 'sell',
                        'price': row['close'],
                        'shares': shares,
                        'capital': capital,
                        'total_value': capital
                    })
                    shares = 0

                # è®°å½•æ¯æ—¥ä»·å€¼
                daily_value = capital + (shares * row['close'] if shares > 0 else 0)
                daily_values.append({
                    'date': date,
                    'value': daily_value,
                    'return': (daily_value / initial_capital - 1) * 100
                })

        if not daily_values:
            logger.warning(f"[{symbol}] å›æµ‹æœŸé—´æ— æœ‰æ•ˆæ•°æ®ï¼Œæ— æ³•ç”Ÿæˆå›æµ‹ç»“æœ")
            return None

        # è®¡ç®—å›æµ‹æŒ‡æ ‡
        df_values = pd.DataFrame(daily_values)
        df_values.set_index('date', inplace=True)
        df_values['cumulative_return'] = (df_values['value'] / initial_capital - 1) * 100

        # è®¡ç®—æœ€å¤§å›æ’¤
        df_values['peak'] = df_values['value'].cummax()
        df_values['drawdown'] = (df_values['value'] - df_values['peak']) / df_values['peak'] * 100
        max_drawdown = df_values['drawdown'].min()

        # è®¡ç®—å¹´åŒ–æ”¶ç›Šç‡
        start_date = df_values.index[0]
        end_date = df_values.index[-1]
        days = (end_date - start_date).days
        annual_return = (df_values['value'].iloc[-1] / initial_capital) ** (365 / days) - 1
        annual_return_pct = annual_return * 100

        # è®¡ç®—å¤æ™®æ¯”ç‡
        daily_returns = df_values['value'].pct_change().dropna()
        sharpe_ratio = (daily_returns.mean() / daily_returns.std()) * np.sqrt(252) if daily_returns.std() != 0 else 0

        # è®¡ç®—èƒœç‡
        if trades:
            winning_trades = [t for t in trades if t['action'] == 'sell' and t['total_value'] > initial_capital]
            win_rate = len(winning_trades) / len(trades) * 100 if len(trades) > 0 else 0
        else:
            win_rate = 0

        # ç”Ÿæˆå›æµ‹ç»“æœ
        backtest_result = {
            'stock_code': symbol,
            'stock_name': name,
            'board': get_market_board(symbol),
            'start_date': start_date.strftime('%Y-%m-%d'),
            'end_date': end_date.strftime('%Y-%m-%d'),
            'initial_capital': initial_capital,
            'final_capital': df_values['value'].iloc[-1],
            'total_return_pct': (df_values['value'].iloc[-1] / initial_capital - 1) * 100,
            'annual_return_pct': annual_return_pct,
            'max_drawdown_pct': max_drawdown,
            'sharpe_ratio': sharpe_ratio,
            'win_rate_pct': win_rate,
            'total_trades': len(trades),
            'daily_values': df_values['cumulative_return'].to_dict()
        }

        # ä¿å­˜å›æµ‹ç»“æœåˆ°æ•°æ®åº“
        save_backtest_result(backtest_result)

        logger.info(f"è‚¡ç¥¨ {symbol} ({name}) çš„AIç­–ç•¥å›æµ‹å®Œæˆ")
        return backtest_result

    except Exception as e:
        logger.error(f"[{symbol}] å›æµ‹å¤±è´¥: {str(e)}", exc_info=True)
        return None


def backtest_ai_strategy_cached(symbol, name, start_date='2023-01-01', end_date='2024-12-31', initial_capital=100000, transaction_cost=0.001):
    """
    å¸¦ç¼“å­˜çš„å›æµ‹AIç­–ç•¥å‡½æ•°
    - symbol: è‚¡ç¥¨ä»£ç 
    - name: è‚¡ç¥¨åç§°
    - start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
    - end_date: å›æµ‹ç»“æŸæ—¥æœŸ
    - initial_capital: åˆå§‹èµ„é‡‘
    - transaction_cost: äº¤æ˜“æˆæœ¬
    """
    # æ£€æŸ¥ç¼“å­˜
    cache_key = f"{symbol}_{start_date}_{end_date}_{initial_capital}_{transaction_cost}"
    now = time.time()
    
    # ç¼“å­˜æœ‰æ•ˆæœŸä¸º24å°æ—¶
    if cache_key in _backtest_cache and (now - _last_backtest_update.get(cache_key, 0) < 24 * 3600):
        logger.info(f"ä½¿ç”¨ç¼“å­˜çš„å›æµ‹ç»“æœ: {symbol} ({name})")
        return _backtest_cache[cache_key]
    
    # æ‰§è¡Œå›æµ‹
    result = backtest_ai_strategy(symbol, name, start_date, end_date, initial_capital, transaction_cost)
    
    # æ›´æ–°ç¼“å­˜
    if result:
        _backtest_cache[cache_key] = result
        _last_backtest_update[cache_key] = now
        logger.info(f"æ›´æ–°å›æµ‹ç¼“å­˜: {symbol} ({name})")
        save_backtest_cache()  # ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶
    
    return result
