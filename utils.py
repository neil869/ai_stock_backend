# utils.py
import pandas as pd
import numpy as np
import time
import warnings
import logging
from datetime import datetime
import os
import pickle
# AkShare è·å–ï¼ˆå¢åŠ é‡è¯•æ¬¡æ•°ã€è¶…æ—¶å¤„ç†å’ŒæŒ‡æ•°é€€é¿ï¼‰
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# å¯¼å…¥æ•°æ®åº“æ“ä½œæ¨¡å—
from db import query_stock_data, check_data_completeness, batch_insert_stock_data, init_db, test_db_connection

# é…ç½®logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('stock_backend.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# è®¾ç½®akshareè¯·æ±‚å¤´
os.environ['AKSHARE_HEADERS'] = '{"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"}'
warnings.filterwarnings('ignore')

try:
    import akshare as ak
    from lightgbm import LGBMClassifier
    from snownlp import SnowNLP
    import jieba
    import baostock as bs
    from db import save_predict_result, query_predict_results  # å¯¼å…¥æ•°æ®åº“æ“ä½œå‡½æ•°
except ImportError as e:
    raise RuntimeError(f"Missing dependency: {e}")

# ==============================
# ğŸ“¦ Baostock åˆå§‹åŒ–
# ==============================
_bs_initialized = False

# ç¼“å­˜æ–‡ä»¶è·¯å¾„å®šä¹‰
STOCKS_CACHE_FILE = 'stocks_cache.pkl'
PREDICT_CACHE_FILE = 'predict_cache.pkl'

# å…¨å±€è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜
_stocks_cache = None
_last_update_date = None

# predict_signalç¼“å­˜
_predict_cache = {}
_last_predict_update = {}

# å®šæ—¶ä»»åŠ¡æ ‡å¿—
_stocks_refreshing = False
_predict_refreshing = False

import threading
import time
from datetime import datetime, timedelta

# è·å–äº¤æ˜“æ—¥å†ç¼“å­˜
_trade_calendar = None
_trade_calendar_updated = None

def get_trade_calendar():
    """
    è·å–äº¤æ˜“æ—¥å†ï¼Œä½¿ç”¨akshareè·å–æ–°æµªè´¢ç»çš„äº¤æ˜“æ—¥å†
    ç¼“å­˜æœºåˆ¶ï¼šæ¯å¤©æ›´æ–°ä¸€æ¬¡æ—¥å†
    """
    global _trade_calendar, _trade_calendar_updated
    today = datetime.today().date()
    
    # å¦‚æœç¼“å­˜ä¸ºç©ºæˆ–è¶…è¿‡ä¸€å¤©æœªæ›´æ–°ï¼Œåˆ™æ›´æ–°ç¼“å­˜
    if _trade_calendar is None or _trade_calendar_updated != today:
        try:
            logger.info("æ›´æ–°äº¤æ˜“æ—¥å†ç¼“å­˜")
            # è·å–1990å¹´è‡³ä»Šçš„äº¤æ˜“æ—¥å†
            df = ak.tool_trade_date_hist_sina()
            # è½¬æ¢ä¸ºæ—¥æœŸç±»å‹
            df['trade_date'] = pd.to_datetime(df['trade_date'], format='%Y%m%d').dt.date
            # åªä¿ç•™äº¤æ˜“æ—¥æœŸåˆ—
            _trade_calendar = set(df['trade_date'])
            _trade_calendar_updated = today
            logger.info("äº¤æ˜“æ—¥å†ç¼“å­˜æ›´æ–°æˆåŠŸ")
        except Exception as e:
            logger.error(f"è·å–äº¤æ˜“æ—¥å†å¤±è´¥: {str(e)}")
            # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å‘¨ä¸€åˆ°å‘¨äº”ä½œä¸ºå¤‡é€‰
            _trade_calendar = None
            _trade_calendar_updated = None
    
    return _trade_calendar

def get_next_trading_day(base_date=None):
    """
    è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ï¼Œè€ƒè™‘å‘¨æœ«å’Œæ³•å®šå‡æœŸ
    
    Args:
        base_date: åŸºå‡†æ—¥æœŸï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å½“å‰æ—¥æœŸ
        
    Returns:
        date: ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥çš„æ—¥æœŸ
    """
    if base_date is None:
        base_date = datetime.today().date()
    elif isinstance(base_date, str):
        base_date = datetime.strptime(base_date, '%Y-%m-%d').date()
    
    trade_calendar = get_trade_calendar()
    
    # ä»åŸºå‡†æ—¥æœŸçš„ä¸‹ä¸€å¤©å¼€å§‹æŸ¥æ‰¾
    next_day = base_date + timedelta(days=1)
    
    while True:
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯äº¤æ˜“æ—¥
        if trade_calendar is not None:
            if next_day in trade_calendar:
                return next_day
        else:
            # å¦‚æœæ²¡æœ‰äº¤æ˜“æ—¥å†ï¼Œä½¿ç”¨ç®€å•çš„å‘¨ä¸€åˆ°å‘¨äº”è§„åˆ™
            if next_day.weekday() < 5:  # 0-4ä»£è¡¨å‘¨ä¸€åˆ°å‘¨äº”
                return next_day
        
        # ä¸æ˜¯äº¤æ˜“æ—¥ï¼Œç»§ç»­æŸ¥æ‰¾ä¸‹ä¸€å¤©
        next_day += timedelta(days=1)

def _init_baostock():
    """
    åˆå§‹åŒ– Baostock è¿æ¥ï¼Œå¢åŠ é‡è¿æœºåˆ¶
    """
    global _bs_initialized
    try:
        # å…ˆå°è¯•ç™»å‡ºæ—§è¿æ¥
        if _bs_initialized:
            bs.logout()
            _bs_initialized = False
            time.sleep(1)  # ç­‰å¾… 1 ç§’åé‡æ–°ç™»å½•
        
        # é‡æ–°ç™»å½•
        lg = bs.login()
        if lg.error_code != '0':
            logger.error(f"[Baostock] Login failed: {lg.error_msg}")
            return False
        else:
            _bs_initialized = True
            logger.info("[Baostock] Login successful")
            return True
    except Exception as e:
        logger.error(f"[Baostock] Login exception: {str(e)}")
        _bs_initialized = False
        return False

def _logout_baostock():
    global _bs_initialized
    if _bs_initialized:
        try:
            bs.logout()
            logger.info("[Baostock] Logout successful")
        except Exception as e:
            logger.error(f"[Baostock] Logout exception: {str(e)}")
        finally:
            _bs_initialized = False

# ==============================
# ğŸ“ ç¼“å­˜æœ¬åœ°æŒä¹…åŒ–åŠŸèƒ½
# ==============================
import pickle

def load_stocks_cache():
    """
    ä»æœ¬åœ°æ–‡ä»¶åŠ è½½è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜
    """
    global _stocks_cache, _last_update_date
    try:
        if os.path.exists(STOCKS_CACHE_FILE):
            with open(STOCKS_CACHE_FILE, 'rb') as f:
                cache_data = pickle.load(f)
                _stocks_cache = cache_data['stocks']
                _last_update_date = cache_data['last_update']
                logger.info(f"ä»æœ¬åœ°ç¼“å­˜åŠ è½½è‚¡ç¥¨åˆ—è¡¨æˆåŠŸï¼Œå…± {len(_stocks_cache)} æ¡æ•°æ®ï¼Œæœ€åæ›´æ–°æ—¥æœŸï¼š{_last_update_date}")
                return True
    except Exception as e:
        logger.error(f"åŠ è½½æœ¬åœ°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜å¤±è´¥ï¼š{e}")
    return False

def save_stocks_cache():
    """
    å°†è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
    """
    global _stocks_cache, _last_update_date
    try:
        if _stocks_cache is not None and _last_update_date is not None:
            cache_data = {
                'stocks': _stocks_cache,
                'last_update': _last_update_date
            }
            with open(STOCKS_CACHE_FILE, 'wb') as f:
                pickle.dump(cache_data, f)
            logger.info(f"è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜å·²ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼š{STOCKS_CACHE_FILE}")
            return True
    except Exception as e:
        logger.error(f"ä¿å­˜è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜åˆ°æœ¬åœ°å¤±è´¥ï¼š{e}")
    return False

def load_predict_cache():
    """
    ä»æ•°æ®åº“åŠ è½½é¢„æµ‹ç»“æœç¼“å­˜
    """
    global _predict_cache, _last_predict_update
    try:
        # ä»æ•°æ®åº“åŠ è½½æœ€è¿‘çš„é¢„æµ‹ç»“æœ
        results = query_predict_results(limit=1000)  # åŠ è½½æœ€è¿‘1000æ¡é¢„æµ‹ç»“æœ
        if results:
            # è½¬æ¢ä¸ºç¼“å­˜æ ¼å¼
            _predict_cache = {}
            _last_predict_update = {}
            for result in results:
                symbol = result['stock_code']
                _predict_cache[symbol] = {
                    'name': result['stock_name'],
                    'stock_code': result['stock_code'],
                    'board': result['board'],
                    'price': result['price'],
                    'signal': result['signal'],
                    'prob': result['prob'],
                    'sentiment_label': result['sentiment_label'],
                    'sentiment_score': result['sentiment_score'],
                    'date': result['predict_date'].strftime('%Y-%m-%d') if hasattr(result['predict_date'], 'strftime') else result['predict_date'],
                    'rsi': result['rsi'],
                    'price_above_bb_upper': result['price_above_bb_upper'],
                    'mom_weakening': result['mom_weakening'],
                    'drawdown_5d': result['drawdown_5d']
                }
                _last_predict_update[symbol] = datetime.now().timestamp()
            logger.info(f"ä»æ•°æ®åº“åŠ è½½é¢„æµ‹ç»“æœæˆåŠŸï¼Œå…± {len(_predict_cache)} æ¡æ•°æ®")
            return True
    except Exception as e:
        logger.error(f"åŠ è½½æ•°æ®åº“é¢„æµ‹ç»“æœç¼“å­˜å¤±è´¥ï¼š{e}")
    return False

def save_predict_cache():
    """
    ä¸å†éœ€è¦å°†é¢„æµ‹ç»“æœç¼“å­˜ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œé¢„æµ‹ç»“æœå·²ç›´æ¥ä¿å­˜åˆ°æ•°æ®åº“
    """
    logger.info("é¢„æµ‹ç»“æœå·²ç›´æ¥ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¸éœ€è¦å†ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶")
    return True

# ============================== 
# ğŸ“Š å·¥å…·å‡½æ•°
# ==============================
def get_market_board(symbol: str) -> str:
    if symbol.startswith('688'):
        return 'ç§‘åˆ›æ¿'
    elif symbol.startswith('300'):
        return 'åˆ›ä¸šæ¿'
    else:
        return 'ä¸»æ¿'

def get_all_stocks(force_refresh=False):
    """
    è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨åˆ—è¡¨
    - force_refresh: æ˜¯å¦å¼ºåˆ¶åˆ·æ–°ç¼“å­˜
    """
    global _stocks_cache, _last_update_date
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ç¼“å­˜ï¼ˆæ¯å¤©æ›´æ–°ä¸€æ¬¡ï¼‰
    current_date = datetime.now().date()
    if _stocks_cache is not None and not force_refresh and _last_update_date == current_date:
        return _stocks_cache.copy()
    
    try:
        # è·å–è‚¡ç¥¨æ•°æ®
        logger.info("å¼€å§‹è·å–æ‰€æœ‰Aè‚¡è‚¡ç¥¨åˆ—è¡¨...")
        df = ak.stock_info_a_code_name()
        logger.info(f"è·å–åˆ° {len(df)} æ¡è‚¡ç¥¨æ•°æ®")
        # ç­›é€‰Aè‚¡è‚¡ç¥¨ï¼ˆä»£ç æ ¼å¼ï¼š6ä½æ•°å­—ï¼Œå‰ç¼€ä¸º0ã€3ã€6ï¼‰
        df = df[df['code'].str.match(r'^[036]\d{5}$')]
        logger.info(f"ç­›é€‰å {len(df)} æ¡è‚¡ç¥¨æ•°æ®")
        
        # è¿‡æ»¤æ‰STã€é€€å¸‚ã€Bè‚¡ç­‰ç‰¹æ®Šè‚¡ç¥¨
        df = df[~df['name'].str.contains('ST|é€€|B', case=False, na=False)]
        logger.info(f"è¿‡æ»¤å {len(df)} æ¡è‚¡ç¥¨æ•°æ®")   
        
        # æ›´æ–°ç¼“å­˜
        _stocks_cache = df
        _last_update_date = current_date
        
        # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
        save_stocks_cache()
        
        logger.info(f"ç¼“å­˜æ›´æ–°å®Œæˆï¼Œå…± {len(df)} æ¡æœ‰æ•ˆè‚¡ç¥¨æ•°æ®")
        
        return df.copy()
    except Exception as e:
        # å¦‚æœè·å–å¤±è´¥ä½†æœ‰ç¼“å­˜ï¼Œè¿”å›ç¼“å­˜æ•°æ®
        if _stocks_cache is not None:
            logger.warning(f"è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥ï¼Œä½†è¿”å›ç¼“å­˜æ•°æ®ï¼š{e}") 
            return _stocks_cache.copy()
        raise RuntimeError(f"Failed to fetch stock list: {e}")

def get_guba_posts(symbol: str, pages=2):
    try:
        df = ak.stock_guba_em(symbol=symbol)
        if df.empty:
            return []
        df = df.sort_values('read_count', ascending=False).head(pages * 20)
        posts = (df['title'].fillna('') + 'ã€‚' + df['content'].fillna('')).tolist()
        return [p for p in posts if len(p) > 10]
    except Exception:
        return []

def basic_sentiment_score(text: str) -> float:
    try:
        s = SnowNLP(text)
        return s.sentiments * 2 - 1
    except:
        return 0.0

def analyze_stock_sentiment(symbol: str) -> dict:
    posts = get_guba_posts(symbol, pages=2)
    if not posts:
        return {"score": 0.0, "label": "â“ æ— æ•°æ®"}
    
    scores = [basic_sentiment_score(p) for p in posts[:30]]
    avg_score = np.mean(scores) if scores else 0.0
    
    if avg_score > 0.3:
        label = "ğŸ”¥ çœ‹æ¶¨"
    elif avg_score < -0.2:
        label = "â„ï¸ çœ‹è·Œ"
    else:
        label = "ğŸ˜ ä¸­æ€§"
    
    return {"score": round(avg_score, 3), "label": label}

# ==============================
# ğŸ“ˆ æ•°æ®è·å–ï¼ˆåŒæºå®¹é”™ + æ•°æ®åº“ç¼“å­˜ï¼‰
# ==============================
def get_stock_daily(symbol: str):
    """
    åŒæºå®¹é”™è·å–ä¸ªè‚¡æ—¥çº¿æ•°æ®ï¼ˆä¼˜å…ˆä»æ•°æ®åº“è·å–ï¼Œå…¶æ¬¡æœ¬åœ°ç¼“å­˜ï¼Œæœ€åå¤–éƒ¨APIï¼‰
    è¿”å›æ ‡å‡† DataFrameï¼šindex=datetime, columns=[open, high, low, close, volume]
    volume å•ä½ï¼šè‚¡ï¼ˆéæ‰‹ï¼‰
    """
    # 1. é¦–å…ˆä»æ•°æ®åº“è·å–æ•°æ®
    logger.info(f"[{symbol}] å°è¯•ä»æ•°æ®åº“è·å–æ•°æ®...")
    
    # æ£€æŸ¥æ•°æ®åº“ä¸­æ•°æ®æ˜¯å¦å®Œæ•´
    is_complete = check_data_completeness(symbol)
    if is_complete:
        # æ•°æ®å®Œæ•´ï¼Œç›´æ¥ä»æ•°æ®åº“è·å–
        df_db = query_stock_data(symbol)
        if not df_db.empty:
            logger.info(f"[{symbol}] ä»æ•°æ®åº“è·å–åˆ°å®Œæ•´æ•°æ®ï¼Œå…± {len(df_db)} æ¡")
            
            # æ£€æŸ¥å½“å‰æ—¶é—´æ˜¯å¦åœ¨äº¤æ˜“æ—¶æ®µ
            today = datetime.now().date()
            current_time = datetime.now()
            current_hour = current_time.hour
            current_minute = current_time.minute
            
            # è·å–äº¤æ˜“æ—¥å†
            trade_calendar = get_trade_calendar()
            is_trading_day = today in trade_calendar if trade_calendar is not None else True
            
            # åˆ¤æ–­æ˜¯å¦åœ¨äº¤æ˜“æ—¶æ®µï¼ˆ9:30-11:30, 13:00-15:00ï¼‰
            is_trading_hours = False
            if 9 <= current_hour < 15:
                if (current_hour == 9 and current_minute >= 30) or (10 <= current_hour < 11) or (current_hour == 11 and current_minute <= 30) or (13 <= current_hour < 15):
                    is_trading_hours = True
            
            logger.info(f"å½“å‰æ—¶é—´: {current_time}, æ˜¯äº¤æ˜“æ—¥: {is_trading_day}, æ˜¯äº¤æ˜“æ—¶é—´: {is_trading_hours}")
            
            # å¦‚æœæ˜¯äº¤æ˜“æ—¥å¹¶ä¸”åœ¨äº¤æ˜“æ—¶æ®µï¼Œé‡æ–°è·å–å½“å¤©çš„æ•°æ®
            if is_trading_day and is_trading_hours:
                logger.info(f"[{symbol}] å½“å¤©äº¤æ˜“æ—¶æ®µï¼Œé‡æ–°è·å–å½“å¤©æ•°æ®")
                
                # æ„é€ æŸ¥è¯¢æ¡ä»¶ï¼Œåªè·å–å½“å¤©çš„æ•°æ®
                today_str = today.strftime("%Y%m%d")
                
                try:
                    # ä¸ºAkShareé…ç½®è¯·æ±‚é‡è¯•ç­–ç•¥
                    session = requests.Session()
                    retry_strategy = Retry(
                        total=3,
                        status_forcelist=[429, 500, 502, 503, 504],
                        allowed_methods=["HEAD", "GET", "OPTIONS"],
                        backoff_factor=1  # æŒ‡æ•°é€€é¿
                    )
                    adapter = HTTPAdapter(max_retries=retry_strategy)
                    session.mount("http://", adapter)
                    session.mount("https://", adapter)
                    
                    # è®¾ç½®å…¨å±€è¶…æ—¶
                    session.timeout = 10  # 10ç§’è¶…æ—¶
                    
                    # æ›¿æ¢AkShareçš„é»˜è®¤ä¼šè¯
                    ak._session = session
                    
                    # è·å–å½“å¤©çš„æ•°æ®
                    df_today = ak.stock_zh_a_hist(
                        symbol=symbol,
                        period="daily",
                        start_date=today_str,
                        end_date=today_str,
                        adjust="qfq"
                    )
                    
                    if not df_today.empty:
                        # é‡å‘½åä¸­æ–‡åˆ—
                        df_today.rename(columns={
                            'æ—¥æœŸ': 'date',
                            'å¼€ç›˜': 'open',
                            'æœ€é«˜': 'high',
                            'æœ€ä½': 'low',
                            'æ”¶ç›˜': 'close',
                            'æˆäº¤é‡': 'volume',      # å•ä½ï¼šæ‰‹
                            'æˆäº¤é¢': 'amount',
                            'æ¶¨è·Œå¹…': 'pct_chg',
                            'æ¢æ‰‹ç‡': 'turnover'
                        }, inplace=True)
                        df_today['date'] = pd.to_datetime(df_today['date'])
                        df_today.set_index('date', inplace=True)
                        df_today.sort_index(inplace=True)
                        # è½¬æ¢æˆäº¤é‡ä¸ºâ€œè‚¡â€
                        df_today['volume'] = df_today['volume'] * 100
                        # æ¸…æ´—å¼‚å¸¸å€¼
                        df_today = df_today[
                            (df_today['close'] > 0.1) &
                            (df_today['close'] < 1000) &
                            (df_today['volume'] >= 0)
                        ]
                        
                        if not df_today.empty:
                            # æ›´æ–°æ•°æ®åº“
                            save_df = df_today[['open', 'high', 'low', 'close', 'volume']].copy().reset_index()
                            batch_insert_stock_data(save_df, symbol)
                            
                            # æ›´æ–°å†…å­˜ä¸­çš„æ•°æ®
                            if today in df_db.index.date:
                                # å¦‚æœæ•°æ®åº“ä¸­å·²æœ‰å½“å¤©çš„æ•°æ®ï¼Œæ›¿æ¢å®ƒ
                                df_db = df_db[df_db.index.date != today]
                                df_db = pd.concat([df_db, df_today])
                                df_db.sort_index(inplace=True)
                            else:
                                # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰å½“å¤©çš„æ•°æ®ï¼Œæ·»åŠ å®ƒ
                                df_db = pd.concat([df_db, df_today])
                                df_db.sort_index(inplace=True)
                            
                            logger.info(f"[{symbol}] æˆåŠŸæ›´æ–°å½“å¤©æ•°æ®")
                        else:
                            logger.warning(f"[{symbol}] å½“å¤©æ•°æ®å¼‚å¸¸ï¼Œä¸æ›´æ–°")
                    else:
                        logger.warning(f"[{symbol}] æœªè·å–åˆ°å½“å¤©æ•°æ®")
                except Exception as e:
                    logger.warning(f"[{symbol}] è·å–å½“å¤©æ•°æ®å¤±è´¥: {str(e)[:100]}")
            
            return df_db
        else:
            logger.warning(f"[{symbol}] æ•°æ®åº“æŸ¥è¯¢æ— ç»“æœ")
    else:
        logger.info(f"[{symbol}] æ•°æ®åº“æ•°æ®ä¸å®Œæ•´ï¼Œéœ€è¦ä»å¤–éƒ¨APIè·å–æ•°æ®")
    
    # ä¸ºAkShareé…ç½®è¯·æ±‚é‡è¯•ç­–ç•¥
    session = requests.Session()
    retry_strategy = Retry(
        total=3,
        status_forcelist=[429, 500, 502, 503, 504],
        allowed_methods=["HEAD", "GET", "OPTIONS"],
        backoff_factor=1  # æŒ‡æ•°é€€é¿
    )
    adapter = HTTPAdapter(max_retries=retry_strategy)
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    
    # è®¾ç½®å…¨å±€è¶…æ—¶
    session.timeout = 10  # 10ç§’è¶…æ—¶
    
    for attempt in range(3):  # å¢åŠ åˆ°3æ¬¡é‡è¯•
        try:
            # æ›¿æ¢AkShareçš„é»˜è®¤ä¼šè¯
            ak._session = session
            
            df_ak = ak.stock_zh_a_hist(
                symbol=symbol,
                period="daily",
                start_date="20100101",
                end_date=pd.Timestamp.today().strftime("%Y%m%d"),
                adjust="qfq"
            )
            if not df_ak.empty:
                # é‡å‘½åä¸­æ–‡åˆ—
                df_ak.rename(columns={
                    'æ—¥æœŸ': 'date',
                    'å¼€ç›˜': 'open',
                    'æœ€é«˜': 'high',
                    'æœ€ä½': 'low',
                    'æ”¶ç›˜': 'close',
                    'æˆäº¤é‡': 'volume',      # å•ä½ï¼šæ‰‹
                    'æˆäº¤é¢': 'amount',
                    'æ¶¨è·Œå¹…': 'pct_chg',
                    'æ¢æ‰‹ç‡': 'turnover'
                }, inplace=True)
                df_ak['date'] = pd.to_datetime(df_ak['date'])
                df_ak.set_index('date', inplace=True)
                df_ak.sort_index(inplace=True)
                # è½¬æ¢æˆäº¤é‡ä¸ºâ€œè‚¡â€
                df_ak['volume'] = df_ak['volume'] * 100
                # æ¸…æ´—å¼‚å¸¸å€¼
                df_ak = df_ak[
                    (df_ak['close'] > 0.1) &
                    (df_ak['close'] < 1000) &
                    (df_ak['volume'] >= 0)
                ]
                if len(df_ak) >= 100:
                    # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆä¿å­˜å®Œæ•´æ•°æ®ï¼ŒåŒ…æ‹¬å½“å¤©å¯èƒ½æœªæ”¶ç›˜çš„æ•°æ®ï¼‰
                    save_df = df_ak[['open', 'high', 'low', 'close', 'volume']].copy().reset_index()
                    batch_insert_stock_data(save_df, symbol)
                    
                    # ä¸å†ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜ï¼Œæ•°æ®å·²ç›´æ¥ä¿å­˜åˆ°æ•°æ®åº“
                    
                    # è¿”å›å®Œæ•´æ•°æ®
                    return df_ak[['open', 'high', 'low', 'close', 'volume']].copy()
                else:
                    logger.warning(f"[{symbol}] AkShare æ•°æ®ä¸è¶³ï¼ˆ{len(df_ak)} æ¡ï¼‰")
        except Exception as e:
            err_str = str(e)
            logger.warning(f"[{symbol}] AkShare å°è¯• {attempt+1}/3 å¤±è´¥: {err_str[:120]}")
        time.sleep(2)  # å¢åŠ ç­‰å¾…æ—¶é—´

    # === é™çº§åˆ° Baostock ===
    for attempt in range(3):  # Baostock ä¹Ÿå¢åŠ é‡è¯•æ¬¡æ•°
        try:
            # ç¡®ä¿ Baostock è¿æ¥æœ‰æ•ˆï¼Œå¦‚æœå¤±è´¥åˆ™é‡æ–°è¿æ¥
            if not _bs_initialized or not _init_baostock():
                logger.warning(f"[{symbol}] Baostock è¿æ¥å¤±è´¥ï¼Œå°è¯•é‡æ–°è¿æ¥...")
                if not _init_baostock():
                    time.sleep(2)
                    continue
            
            # æ„é€ ä»£ç 
            if symbol.startswith(('6', '9')):
                code = f"sh.{symbol}"
            else:
                code = f"sz.{symbol}"
            
            rs = bs.query_history_k_data_plus(
                code,
                "date,open,high,low,close,volume,amount",
                start_date="2010-01-01",
                end_date=pd.Timestamp.today().strftime("%Y-%m-%d"),
                frequency="d",
                adjustflag="3"  # åå¤æƒ
            )
            
            # æ£€æŸ¥æŸ¥è¯¢æ˜¯å¦æˆåŠŸ
            if rs.error_code != '0':
                logger.error(f"[{symbol}] Baostock æŸ¥è¯¢å¤±è´¥: {rs.error_msg}")
                # æŸ¥è¯¢å¤±è´¥å¯èƒ½æ˜¯è¿æ¥å¤±æ•ˆï¼Œé‡æ–°åˆå§‹åŒ–è¿æ¥
                _logout_baostock()
                time.sleep(1)
                continue
            
            data_list = []
            while rs.next():
                data_list.append(rs.get_row_data())
            
            if not data_list:
                logger.warning(f"[{symbol}] Baostock æ— æ•°æ®")
                continue

            df_bs = pd.DataFrame(data_list, columns=['date','open','high','low','close','volume','amount'])
            df_bs['date'] = pd.to_datetime(df_bs['date'])
            df_bs.set_index('date', inplace=True)
            df_bs.sort_index(inplace=True)
            
            # è½¬æ¢æ•°å€¼ç±»å‹
            for col in ['open','high','low','close','volume','amount']:
                df_bs[col] = pd.to_numeric(df_bs[col], errors='coerce')
            df_bs.dropna(inplace=True)
            
            # æ¸…æ´—
            df_bs = df_bs[
                (df_bs['close'] > 0.1) &
                (df_bs['close'] < 1000) &
                (df_bs['volume'] >= 0)
            ]
            
            if len(df_bs) >= 100:
                # ä¿å­˜åˆ°æ•°æ®åº“
                save_df = df_bs[['open', 'high', 'low', 'close', 'volume']].copy().reset_index()
                batch_insert_stock_data(save_df, symbol)
            else:
                logger.warning(f"[{symbol}] Baostock æ•°æ®ä¸è¶³ï¼ˆ{len(df_bs)} æ¡ï¼‰")
                continue

        except Exception as e:
            logger.error(f"[{symbol}] Baostock å°è¯• {attempt+1}/3 å¤±è´¥: {str(e)[:120]}")
            # å¼‚å¸¸æ—¶é‡æ–°åˆå§‹åŒ–è¿æ¥
            _logout_baostock()
        time.sleep(2)  # å¢åŠ ç­‰å¾…æ—¶é—´
    return pd.DataFrame()

# ==============================
# ğŸ¤– ç‰¹å¾ä¸é¢„æµ‹
# ==============================
def calc_features_safe(df_slice):
    if len(df_slice) < 60:
        return None
    high = df_slice['high']
    low = df_slice['low']
    close = df_slice['close']
    volume = df_slice['volume']
    
    features = {}
    features['mom_5'] = close.iloc[-1] / close.iloc[-6] - 1 if len(close) >= 6 else 0
    features['mom_20'] = close.iloc[-1] / close.iloc[-21] - 1 if len(close) >= 21 else 0
    
    ma5 = close.tail(5).mean()
    ma20 = close.tail(20).mean()
    ma60 = close.tail(60).mean() if len(close) >= 60 else ma20
    features['ma5'] = ma5
    features['ma20'] = ma20
    features['ma60'] = ma60
    features['ma_align'] = int(ma5 > ma20 > ma60)
    features['price_to_ma20'] = (close.iloc[-1] - ma20) / ma20

    if len(close) >= 15:
        delta = close.diff().iloc[-14:]
        gain = delta.where(delta > 0, 0).mean()
        loss = (-delta.where(delta < 0, 0)).mean()
        rs = gain / loss if loss != 0 else 0
        features['rsi_14'] = 100 - (100 / (1 + rs)) if rs != 0 else 50
    else:
        features['rsi_14'] = 50

    if len(close) >= 26:
        ema12 = close.ewm(span=12, adjust=False).mean().iloc[-1]
        ema26 = close.ewm(span=26, adjust=False).mean().iloc[-1]
        dif = ema12 - ema26
        dif_series = close.ewm(span=12).mean() - close.ewm(span=26).mean()
        dea = dif_series.tail(9).mean()
        hist = (dif - dea) * 2
        features['macd_dif'] = dif
        features['macd_dea'] = dea
        features['macd_hist'] = hist
        features['macd_bullish'] = int(hist > 0)
    else:
        features.update({'macd_dif':0, 'macd_dea':0, 'macd_hist':0, 'macd_bullish':0})

    vol_ma5 = volume.tail(5).mean()
    features['vol_ratio_5'] = volume.iloc[-1] / vol_ma5 if vol_ma5 != 0 else 1

    if len(close) >= 20:
        bb_ma = close.tail(20).mean()
        bb_std = close.tail(20).std()
        bb_upper = bb_ma + 2 * bb_std
        bb_lower = bb_ma - 2 * bb_std
        price = close.iloc[-1]
        features['bb_width'] = (bb_upper - bb_lower) / bb_ma
        features['bb_position'] = (price - bb_lower) / (bb_upper - bb_lower) if bb_upper != bb_lower else 0.5
        features['price_above_bb_upper'] = int(price > bb_upper)
        features['price_below_bb_lower'] = int(price < bb_lower)
    else:
        features.update({'bb_width':0, 'bb_position':0.5, 'price_above_bb_upper':0, 'price_below_bb_lower':0})

    return pd.Series(features)

def predict_signal(symbol, name, train_window=200,):
    """
    é¢„æµ‹è‚¡ç¥¨ä¹°å–ä¿¡å·
    - symbol: è‚¡ç¥¨ä»£ç 
    - name: è‚¡ç¥¨åç§°
    - train_window: è®­ç»ƒçª—å£å¤§å°
    """
    logger.info(f"å¼€å§‹é¢„æµ‹è‚¡ç¥¨ {symbol} ({name}) çš„ä¿¡å·")
    try:
        # åˆ¤æ–­å½“å‰æ—¶é—´æ˜¯å¦åœ¨å¼€ç›˜æ—¥çš„äº¤æ˜“æ—¶æ®µï¼ˆ9:30-11:30, 13:00-15:00ï¼‰
        current_time = datetime.now()
        current_date = current_time.date()
        current_hour = current_time.hour
        current_minute = current_time.minute
        current_seconds = current_time.second
        
        # è·å–äº¤æ˜“æ—¥å†
        trade_calendar = get_trade_calendar()
        
        # åˆ¤æ–­æ˜¯å¦ä¸ºå¼€ç›˜æ—¥çš„äº¤æ˜“æ—¶æ®µ
        is_trading_day = current_date in trade_calendar if trade_calendar is not None else True
        is_trading_hours = False
        if 9 <= current_hour < 15:
            if (current_hour == 9 and current_minute >= 30) or (10 <= current_hour < 11) or (current_hour == 11 and current_minute <= 30) or (13 <= current_hour < 15):
                is_trading_hours = True
        # ç¡®ä¿15ç‚¹æ•´ä¹‹åä¸å¤„ç†
        if current_hour >= 15 and (current_minute > 0 or current_seconds > 0):
            is_trading_hours = False
        
        logger.info(f"å½“å‰æ—¶é—´: {current_time}, æ˜¯äº¤æ˜“æ—¥: {is_trading_day}, æ˜¯äº¤æ˜“æ—¶é—´: {is_trading_hours}")
        
        # è·å–è‚¡ç¥¨æ•°æ®
        df = get_stock_daily(symbol)
        if df is None or df.empty or len(df) < train_window + 1:
            logger.warning(f"[{symbol}] æ•°æ®ä¸è¶³æˆ–è·å–å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œé¢„æµ‹")
            return None
    
        # è·å–æœ€æ–°æ•°æ®æ—¥æœŸ
        latest_data_date = df.index[-1].date()
        
        # è·å–ä¸‹ä¸€ä¸ªäº¤æ˜“æ—¥ä½œä¸ºé¢„æµ‹æ—¥æœŸ
        predict_date = get_next_trading_day(latest_data_date)
        predict_date_str = predict_date.strftime('%Y-%m-%d')
        
        as_of_date = df.index[-1]
        train_dates = df.index[-(train_window + 1):-1]

        X_train = []
        y_train = []

        for d in train_dates:
            idx = df.index.get_loc(d)
            if idx + 1 >= len(df):
                continue
            next_day = df.index[idx + 1]
            df_upto_d = df.loc[:d]
            feat = calc_features_safe(df_upto_d)
            if feat is None:
                continue
            X_train.append(feat)
            ret = (df.loc[next_day, 'close'] - df.loc[d, 'close']) / df.loc[d, 'close']
            y_train.append(int(ret > 0))

        if len(X_train) < 50:
            return None

        X_train = pd.DataFrame(X_train)
        y_train = np.array(y_train)

        from sklearn.utils.class_weight import compute_class_weight
        classes = np.unique(y_train)
        class_weight = dict(zip(classes, compute_class_weight('balanced', classes=classes, y=y_train))) if len(classes) == 2 else None

        model = LGBMClassifier(
            n_estimators=80,
            max_depth=4,
            random_state=42,
            verbose=-1,
            class_weight=class_weight
        )
        model.fit(X_train, y_train)

        feat_pred = calc_features_safe(df[df.index <= as_of_date])
        if feat_pred is None:
            return None
        feat_pred = feat_pred.reindex(X_train.columns, fill_value=0)
        prob = model.predict_proba([feat_pred])[0][1]

        close = df['close']
        latest_close = close.iloc[-1]
        rsi = feat_pred.get('rsi_14', 50)
        price_above_bb = bool(feat_pred.get('price_above_bb_upper', 0))
        
        mom_weakening = False
        if len(close) >= 11:
            mom_recent = close.iloc[-1] / close.iloc[-6] - 1
            mom_prev = close.iloc[-6] / close.iloc[-11] - 1
            if mom_prev != 0:
                mom_weakening = mom_recent < mom_prev * 0.5

        drawdown_5d = 0
        if len(close) >= 5:
            recent_high = close.tail(5).max()
            if recent_high > 0:
                drawdown_5d = (recent_high - latest_close) / recent_high

        signal = "âšª è§‚æœ›"
        if prob > 0.60 and rsi < 70 and not price_above_bb and not mom_weakening:
            signal = "ğŸŸ¢ å»ºä»“"
        elif prob > 0.55 and rsi < 75:
            signal = "ğŸŸ¡ æŒæœ‰"
        elif (prob < 0.50) or (rsi > 75) or (price_above_bb and mom_weakening) or (drawdown_5d > 0.08):
            signal = "ğŸ”´ å‡ä»“"
        else:
            signal = "ğŸŸ¡ æŒæœ‰"

        senti = analyze_stock_sentiment(symbol)
        
        # ç”Ÿæˆé¢„æµ‹ç†ç”±
        reasons = []
        
        # åŸºäºé¢„æµ‹æ¦‚ç‡çš„ç†ç”±
        if prob > 0.60:
            reasons.append(f"AIæ¨¡å‹é¢„æµ‹ä¸Šæ¶¨æ¦‚ç‡ä¸º{round(prob*100, 1)}%ï¼Œå±äºè¾ƒé«˜æ°´å¹³")
        elif prob > 0.50:
            reasons.append(f"AIæ¨¡å‹é¢„æµ‹ä¸Šæ¶¨æ¦‚ç‡ä¸º{round(prob*100, 1)}%ï¼Œå±äºä¸­æ€§åä¸Šæ°´å¹³")
        else:
            reasons.append(f"AIæ¨¡å‹é¢„æµ‹ä¸Šæ¶¨æ¦‚ç‡ä¸º{round(prob*100, 1)}%ï¼Œå±äºè¾ƒä½æ°´å¹³")
        
        # åŸºäºRSIæŒ‡æ ‡çš„ç†ç”±
        if rsi > 75:
            reasons.append(f"RSIæŒ‡æ ‡ä¸º{round(rsi, 1)}ï¼Œå¤„äºè¶…ä¹°åŒºåŸŸï¼ŒçŸ­æœŸä¸Šæ¶¨å‹åŠ›è¾ƒå¤§")
        elif rsi < 30:
            reasons.append(f"RSIæŒ‡æ ‡ä¸º{round(rsi, 1)}ï¼Œå¤„äºè¶…å–åŒºåŸŸï¼ŒçŸ­æœŸä¸‹è·Œç©ºé—´æœ‰é™")
        elif rsi < 70:
            reasons.append(f"RSIæŒ‡æ ‡ä¸º{round(rsi, 1)}ï¼Œå¤„äºåˆç†åŒºé—´ï¼Œå…·æœ‰ä¸Šæ¶¨æ½œåŠ›")
        
        # åŸºäºå¸ƒæ—å¸¦çš„ç†ç”±
        if price_above_bb:
            reasons.append("ä»·æ ¼çªç ´å¸ƒæ—å¸¦ä¸Šè½¨ï¼ŒçŸ­æœŸå¯èƒ½é¢ä¸´å›è°ƒå‹åŠ›")
        
        # åŸºäºåŠ¨é‡çš„ç†ç”±
        if mom_weakening:
            reasons.append("åŠ¨é‡æ­£åœ¨å‡å¼±ï¼Œä¸Šæ¶¨åŠ¨èƒ½ä¸è¶³")
        else:
            reasons.append("åŠ¨é‡ä¿æŒç¨³å®šï¼Œä¸Šæ¶¨åŠ¨èƒ½å……è¶³")
        
        # åŸºäº5æ—¥å›æ’¤çš„ç†ç”±
        if drawdown_5d > 0.08:
            reasons.append(f"5æ—¥å›æ’¤è¾¾åˆ°{round(drawdown_5d*100, 1)}%ï¼ŒçŸ­æœŸè°ƒæ•´å¹…åº¦è¾ƒå¤§")
        
        # åŸºäºæƒ…æ„Ÿåˆ†æçš„ç†ç”±
        if senti["label"] == "æ­£é¢":
            reasons.append(f"å¸‚åœºæƒ…ç»ªä¸º{senti['label']}ï¼Œæœ‰åˆ©äºè‚¡ä»·ä¸Šæ¶¨")
        elif senti["label"] == "è´Ÿé¢":
            reasons.append(f"å¸‚åœºæƒ…ç»ªä¸º{senti['label']}ï¼Œä¸åˆ©äºè‚¡ä»·ä¸Šæ¶¨")
        
        # æ ¹æ®é¢„æµ‹ä¿¡å·å®šåˆ¶ç†ç”±å¼€å¤´
        signal_text = signal.split(' ')[1]  # è·å–ä¿¡å·æ–‡æœ¬éƒ¨åˆ†ï¼ˆå¦‚ï¼šå»ºä»“ã€æŒæœ‰ã€å‡ä»“ã€è§‚æœ›ï¼‰
        reason_prefix = f"{signal_text}ç†ç”±"
        
        # ç»„åˆæœ€ç»ˆç†ç”±
        reason = reason_prefix + "ï¼š" + "ï¼›".join(reasons) + "ã€‚"

        result = {
            "name": name,
            "stock_code": symbol,
            "board": get_market_board(symbol),
            "price": round(latest_close, 2),
            "signal": signal,
            "prob": round(prob * 100, 2),
            "sentiment_label": senti["label"],
            "sentiment_score": senti["score"],
            "date": predict_date_str,
            "rsi": round(rsi, 1),
            "price_above_bb_upper": price_above_bb,
            "mom_weakening": mom_weakening,
            "drawdown_5d": round(drawdown_5d * 100, 2),
            "reason": reason
        }
        
        # å°†é¢„æµ‹ç»“æœä¿å­˜åˆ°æ•°æ®åº“
        save_predict_result(result)
        return result
    except Exception as e:
        logger.error(f"[{symbol}] é¢„æµ‹å¤±è´¥: {str(e)}", exc_info=True)
        return None

def _scheduled_stocks_refresh():
    """
    å®šæ—¶åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜çš„åå°ä»»åŠ¡
    """
    # ç¬¬ä¸€æ¬¡æ‰§è¡Œæ—¶å…ˆç­‰å¾…24å°æ—¶ï¼Œå› ä¸ºstart_scheduled_taskså·²ç»åˆå§‹åŒ–äº†ç¼“å­˜
    time.sleep(86400)
    
    while True:
        try:
            # åˆ·æ–°è‚¡ç¥¨åˆ—è¡¨
            get_all_stocks(force_refresh=True)
            logger.info("è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜å·²æ›´æ–°")
        except Exception as e:
            logger.error(f"æ›´æ–°è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜å¤±è´¥: {e}")
        
        # ç­‰å¾…24å°æ—¶
        time.sleep(86400)

# é…ç½®ç”¨æˆ·é€‰å¥½çš„è‚¡ç¥¨åˆ—è¡¨ï¼Œç”¨äºè‡ªåŠ¨é¢„æµ‹
AUTO_PREDICT_STOCKS = [
    {"code": "601138", "name": "å·¥ä¸šå¯Œè”"},
    {"code": "603336", "name": "å®è¾‰æœè”¬"},
    # å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤šè‚¡ç¥¨
]

# è‡ªåŠ¨é¢„æµ‹ä»»åŠ¡æ‰§è¡Œé—´éš”ï¼ˆç§’ï¼‰
AUTO_PREDICT_INTERVAL = 3600  # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡


def _scheduled_stock_prediction():
    """
    å®šæ—¶æ‰§è¡Œè‚¡ç¥¨è‡ªåŠ¨é¢„æµ‹ä»»åŠ¡
    åœ¨æ¯å¤©æ”¶ç›˜åï¼ˆ15:00ä¹‹åï¼‰è‡ªåŠ¨é¢„æµ‹ç”¨æˆ·é€‰å¥½çš„è‚¡ç¥¨
    """
    logger.info("è‚¡ç¥¨è‡ªåŠ¨é¢„æµ‹ä»»åŠ¡å·²å¯åŠ¨")
    
    while True:
        try:
            # è·å–å½“å‰æ—¶é—´
            current_time = datetime.now()
            current_hour = current_time.hour
            current_minute = current_time.minute
            current_date = current_time.date()
            
            # è·å–äº¤æ˜“æ—¥å†
            trade_calendar = get_trade_calendar()
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºäº¤æ˜“æ—¥
            is_trading_day = current_date in trade_calendar if trade_calendar is not None else True
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ”¶ç›˜åæ—¶é—´ï¼ˆ15:00ä¹‹åï¼‰
            is_after_market_close = current_hour >= 15
            
            logger.info(f"è‡ªåŠ¨é¢„æµ‹æ£€æŸ¥ - å½“å‰æ—¶é—´: {current_time}, æ˜¯äº¤æ˜“æ—¥: {is_trading_day}, æ”¶ç›˜å: {is_after_market_close}")
            
            # ä»…åœ¨äº¤æ˜“æ—¥çš„æ”¶ç›˜åæ‰§è¡Œé¢„æµ‹
            if is_trading_day and is_after_market_close:
                logger.info(f"å¼€å§‹æ‰§è¡Œè‡ªåŠ¨é¢„æµ‹ä»»åŠ¡ï¼Œå…± {len(AUTO_PREDICT_STOCKS)} åªè‚¡ç¥¨")
                
                for stock in AUTO_PREDICT_STOCKS:
                    symbol = stock["code"]
                    name = stock["name"]
                    try:
                        logger.info(f"å¼€å§‹è‡ªåŠ¨é¢„æµ‹è‚¡ç¥¨ {symbol} ({name})")
                        # è°ƒç”¨é¢„æµ‹å‡½æ•°
                        result = predict_signal(symbol, name)
                        if result:
                            logger.info(f"è‚¡ç¥¨ {symbol} ({name}) é¢„æµ‹å®Œæˆï¼š{result['signal']} (æ¦‚ç‡: {result['prob']}%)")
                        else:
                            logger.warning(f"è‚¡ç¥¨ {symbol} ({name}) é¢„æµ‹å¤±è´¥")
                    except Exception as e:
                        logger.error(f"è‡ªåŠ¨é¢„æµ‹è‚¡ç¥¨ {symbol} ({name}) æ—¶å‡ºé”™: {str(e)}")
                        import traceback
                        traceback.print_exc()
                
                logger.info("æ‰€æœ‰è‚¡ç¥¨è‡ªåŠ¨é¢„æµ‹ä»»åŠ¡å®Œæˆ")
            
            # ç­‰å¾…æŒ‡å®šé—´éš”åå†æ¬¡æ£€æŸ¥
            time.sleep(AUTO_PREDICT_INTERVAL)
            
        except Exception as e:
            logger.error(f"è‡ªåŠ¨é¢„æµ‹ä»»åŠ¡æ‰§è¡Œå‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            # å‡ºé”™åç­‰å¾…ä¸€æ®µæ—¶é—´å†é‡è¯•
            time.sleep(300)


def start_scheduled_tasks():
    """
    å¯åŠ¨æ‰€æœ‰å®šæ—¶ä»»åŠ¡
    """
    # å¯åŠ¨æ—¶å…ˆå°è¯•åŠ è½½æœ¬åœ°ç¼“å­˜
    load_stocks_cache()
    
    # åˆå§‹åŒ–æ•°æ®åº“
    init_db()
    
    # å¦‚æœæœ¬åœ°æ²¡æœ‰ç¼“å­˜æˆ–ç¼“å­˜è¿‡æœŸï¼Œåˆå§‹åŒ–è‚¡ç¥¨åˆ—è¡¨ç¼“å­˜
    if _stocks_cache is None:
        get_all_stocks()
    
    # å¯åŠ¨è‚¡ç¥¨åˆ—è¡¨å®šæ—¶æ›´æ–°ä»»åŠ¡
    stocks_thread = threading.Thread(target=_scheduled_stocks_refresh, daemon=True)
    stocks_thread.start()
    
    # å¯åŠ¨è‚¡ç¥¨è‡ªåŠ¨é¢„æµ‹ä»»åŠ¡
    predict_thread = threading.Thread(target=_scheduled_stock_prediction, daemon=True)
    predict_thread.start()
    
    logger.info("æ‰€æœ‰å®šæ—¶æ›´æ–°ä»»åŠ¡å·²å¯åŠ¨")

# ==============================
# ğŸ” å›æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼Œä»…è¿”å›æŒ‡æ ‡ï¼‰
# ==============================
def backtest_ai_strategy_cached(board_filter, top_k, min_prob, lookback_days):
    stocks_df = get_all_stocks()
    if board_filter != "å…¨éƒ¨":
        stocks_df = stocks_df[stocks_df['code'].apply(get_market_board) == board_filter].reset_index(drop=True)

    valid_symbols = []
    all_prices = {}
    for _, row in stocks_df.iterrows():
        symbol = row['code']
        df = get_stock_daily(symbol)
        if not df.empty and len(df) >= lookback_days + 50:
            all_prices[symbol] = df['close']
            valid_symbols.append(symbol)

    if not valid_symbols:
        return None

    common_dates = set(all_prices[valid_symbols[0]].index)
    for sym in valid_symbols[:5]:
        common_dates &= set(all_prices[sym].index)
    common_dates = sorted(common_dates)[-lookback_days:]
    if len(common_dates) < 30:
        return None

    nav = 1.0
    daily_rets = []

    for i in range(len(common_dates) - 1):
        t0 = common_dates[i]
        t1 = common_dates[i + 1]

        signals = []
        for sym in valid_symbols[:100]:  # é™100åªé˜²è¶…æ—¶
            if t0 not in all_prices[sym].index or t1 not in all_prices[sym].index:
                continue
            try:
                full_df = get_stock_daily(sym)
                if t0 not in full_df.index:
                    continue
                df_upto_t0 = full_df[full_df.index <= t0]
                feat = calc_features_safe(df_upto_t0)
                if feat is None:
                    continue
                prob = 0.52  # ç®€åŒ–ï¼šå®é™…åº”è®­ç»ƒæ¨¡å‹é¢„æµ‹
                if prob >= min_prob / 100.0:
                    ret = (all_prices[sym].loc[t1] - all_prices[sym].loc[t0]) / all_prices[sym].loc[t0]
                    signals.append((prob, ret))
            except Exception:
                continue

        signals.sort(reverse=True)
        selected = signals[:top_k]
        daily_ret = np.mean([r for _, r in selected]) if selected else 0.0
        nav *= (1 + daily_ret)
        daily_rets.append(daily_ret)

    returns = pd.Series(daily_rets)
    total_ret = nav - 1
    annual_ret = (1 + total_ret) ** (252 / len(daily_rets)) - 1 if len(daily_rets) > 0 else 0
    vol = returns.std() * np.sqrt(252)
    sharpe = annual_ret / vol if vol != 0 else 0
    dd = (pd.Series(nav).cummax() - pd.Series(nav)) / pd.Series(nav).cummax()
    mdd = dd.max()
    win_rate = (returns > 0).mean()

    return {
        'total_return': float(total_ret),
        'annualized_return': float(annual_ret),
        'sharpe': float(sharpe),
        'max_drawdown': float(mdd),
        'win_rate': float(win_rate)
    }